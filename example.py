# -*- coding: utf-8 -*-

from invada import matcher_parser, macro_definitions_parser, MatcherBuilder, ResponsePair, Engine
import unicodedata

ontology = {
    '#æœç‰©': {'#ã‚Šã‚“ã”', '#ã¿ã‹ã‚“', '#ã¶ã©ã†'},
    '#ã‚Šã‚“ã”': {'æ—æª', 'ã‚Šã‚“ã”', 'ãƒªãƒ³ã‚´'},
    '#ã¿ã‹ã‚“': {'èœœæŸ‘', 'ã¿ã‹ã‚“', 'ãƒŸã‚«ãƒ³'},
    '#ã¶ã©ã†': {'è‘¡è„', 'ã¶ã©ã†', 'ãƒ–ãƒ‰ã‚¦'},
}

macros = macro_definitions_parser.parse('''
%twice(a) = $a $a ;
%tell_me(a) = $a ã«ã¤ã„ã¦æ•™ãˆã¦|$a ã‚’æ•™ãˆã¦|$a æ•™ãˆã¦|$a ã£ã¦ä½•|$a ã£ã¦ä½•? ;
%color() = èµ¤ | é’ | é»„ ;
''')

phrases = {
    'ä½•': matcher_parser.parse('ä½• | ãªã«'),
    'ç§': matcher_parser.parse('ç§ | ã‚ãŸã—'),
    'åå‰': matcher_parser.parse('åå‰ | ãªã¾ãˆ'),
}


def merge(source, target):
    for key in source:
        if key not in target:
            target[key] = source[key]
    return target

raw_response_pairs = [
    ('ã“ã‚“ã«ã¡ã¯',
     lambda captured, context, knowledge: 1,
     lambda captured, context, knowledge: ('ã“ã‚“ã¡ã‚ƒãƒ¼ã™', context)),
    ('ã“ã‚“ã«ã¡ã¯',
     lambda captured, context, knowledge: 2 if 'name' in context else 0,
     lambda captured, context, knowledge:
     ('{}ã•ã‚“ã“ã‚“ã¡ã‚ƒãƒ¼ã™'.format(context['name']), context)),
    ('#æœç‰©@æœç‰© ãŒå¥½ãã§ã™',
     lambda captured, context, knowledge: 1,
     lambda captured, context, knowledge: ('{}å¥½ããªã‚“ã '.format(captured['æœç‰©']['raw']), context)),
    ('%twice(ã“ã‚“ã«ã¡ã¯)',
     lambda captured, context, knowledge: 1,
     lambda captured, context, knowledge: ('ã¯ã¾ã¡ã¡ã‚ƒã‚“ã‹ãªï¼Ÿ', context)),
    ('%twice(ã‚)',
     lambda captured, context, knowledge: 1,
     lambda captured, context, knowledge: ('ã‚ã‚ï¼Ÿ', context)),
    ('%tell_me(#æœç‰©@æœç‰©)',
     lambda captured, context, knowledge: 1,
     lambda captured, context, knowledge: ('{}ã¯{}ã‚ˆ'.format(captured['æœç‰©']['raw'], knowledge['æœç‰©'][captured['æœç‰©']['entity']]), context)),
    ('%color()',
     lambda captured, context, knowledge: 1,
     lambda captured, context, knowledge: ('è‰²ã§ã™ã‹ï¼Ÿ', context)),
    ('ç§ã®åå‰ã¯ *@name ã§ã™',
     lambda captured, context, knowledge: 1,
     lambda captured, context, knowledge:
     ('{}ã•ã‚“ã§ã™ã­ï¼'.format(captured['name']),
      merge(context, {'name': captured['name']}))),
    ('*',
     lambda captured, context, knowledge: 0.01,
     lambda captured, context, knowledge: ('ãˆã£ï¼Ÿ', context)),
    ('* (å¯¿å¸ | ã™ã—) *',
     lambda captured, context, knowledge: 0.02,
     lambda captured, context, knowledge: ('ğŸ£', context)),
    ('$empty',
     lambda captured, context, knowledge: 1,
     lambda captured, context, knowledge: ('ãªã«ã‹è¨€ã£ã¦ã‚ˆï¼', context)),
]

knowledge = {
    'æœç‰©': {
        '#ã‚Šã‚“ã”': 'èµ¤ãã¦ä¸¸ã„',
        '#ã¿ã‹ã‚“': 'ã„ã‚ã‚“ãªç¨®é¡ãŒã‚ã‚‹',
        '#ã¶ã©ã†': 'ãƒ¯ã‚¤ãƒ³ã®åŸæ–™ã ',
    }
}


if __name__ == '__main__':

    matcher_builder = MatcherBuilder(ontology, macros, phrases)

    def make_response_pair(raw_response_pair):
        matcher, scorer, generator = raw_response_pair
        return ResponsePair(matcher_builder.build(matcher),
                            scorer,
                            generator)

    response_pairs = [make_response_pair(raw_response_pair)
                      for raw_response_pair in raw_response_pairs]

    engine = Engine(response_pairs, knowledge=knowledge)

    context = {}

    print('ã„ã‚‰ã£ã—ã‚ƒã„ã¾ã›ï¼')
    while True:
        user_utterance = input()
        user_utterance = unicodedata.normalize('NFKC', user_utterance)
        bot_utterance, context = engine.chat(user_utterance, context)
        print(bot_utterance)
